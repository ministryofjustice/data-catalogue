name: "Ingest DBT metadata from Create a Derived Table"

permissions:
  id-token: write
  contents: read

on:
  workflow_call:
    inputs:
      ECR_REGION:
        description: "ecr region to connect to"
        required: false
        type: string
        default: eu-west-1
      ENVIRONMENT:
        description: "Environment to use for secrets"
        required: true
        type: string
      CADET_INGESTION_RECIPE_PATH:
        description: "Path to the ingestion recipe"
        required: true
        type: string
      BASE_CADET_INGESTION:
        description: "Whether to run the base cadet ingestion prep steps"
        type: boolean
        default: true
      S3_TARGET_LOCATION:
        description: "S3 location to target for cadet manifest"
        type: string
        required: true
      CADET_INSTANCE:
        description: "Instance name for AssignDatabase transformer mappings to be built"
        type: string
        required: false
        default: "cadet.awsdatacatalog"
    secrets:
      DATAHUB_GMS_TOKEN:
        description: "API Key for datahub GMS"
        required: true
      CADET_METADATA_ROLE_TO_ASSUME:
        description: "AWS role to assume, which can access CaDeT metadata in S3"
        required: true
      SLACK_ALERT_WEBHOOK:
        description: "Webhook for posting alerts to the team"
        required: true

jobs:
  datahub-ingest:
    environment: ${{ inputs.ENVIRONMENT }}
    timeout-minutes: 240
    runs-on: ubuntu-latest
    steps:
      - run: echo "ENVIRONMENT=${{inputs.ENVIRONMENT}}; URL=${{vars.DATAHUB_GMS_URL}}"
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.CADET_METADATA_ROLE_TO_ASSUME }}
          role-duration-seconds: 14400
          aws-region: ${{ inputs.ECR_REGION }}

      - name: cache poetry install
        uses: actions/cache@v4
        with:
          path: ~/.local
          key: poetry-1.7.1-0

      - uses: snok/install-poetry@v1
        with:
          version: 1.7.1
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: cache deps
        id: cache-deps
        uses: actions/cache@v4
        with:
          path: .venv
          key: pydeps-${{ hashFiles('**/poetry.lock') }}
      - run: poetry install --no-interaction --no-root
        if: steps.cache-deps.outputs.cache-hit != 'true'
      - run: poetry install --no-interaction

      - name: Inject S3 location to cadet databases
        env:
          S3_TARGET_LOCATION: ${{ inputs.S3_TARGET_LOCATION }}
        run: |
          mkdir -p ingestion/processed
          envsubst < ingestion/create_cadet_databases.yaml > ingestion/processed/create_cadet_databases.yaml

      - name: Create cadet domains and databases
        env:
          DATAHUB_GMS_TOKEN: ${{ secrets.DATAHUB_GMS_TOKEN }}
          DATAHUB_GMS_URL: ${{ vars.DATAHUB_GMS_URL }}
          DATAHUB_TELEMETRY_ENABLED: false
          CADET_INSTANCE: ${{ inputs.CADET_INSTANCE }}
        run: time poetry run datahub ingest -c ingestion/processed/create_cadet_databases.yaml

      - name: Collate run results paths from cadet runs
        if: ${{ inputs.BASE_CADET_INGESTION }}
        run: poetry run python ingestion/cadet_run_results.py

      - name: push metadata to datahub
        id: push_datahub
        env:
          DATAHUB_GMS_TOKEN: ${{ secrets.DATAHUB_GMS_TOKEN }}
          DATAHUB_GMS_URL: ${{ vars.DATAHUB_GMS_URL }}
          DATAHUB_TELEMETRY_ENABLED: false
          CADET_INSTANCE: ${{ inputs.CADET_INSTANCE }}
        run: |
          time poetry run datahub ingest -c ${{ inputs.CADET_INGESTION_RECIPE_PATH }} --report-to output.json || true
          if [ ! -f output.json ]; then
            echo "Ingestion output file not found. Failing the job."
            exit 1
          fi
          SINK_FAILURE_COUNT=$(jq '.sink.report.failures | length' output.json)
          SOURCE_FAILURE_COUNT=$(jq '.source.report.failures | length' output.json)
          echo "sink_failure_count=$SINK_FAILURE_COUNT" >> $GITHUB_ENV
          echo "source_failure_count=$SOURCE_FAILURE_COUNT" >> $GITHUB_ENV

      - name: Notify on unexpected ingestion failures
        uses: slackapi/slack-github-action@v1.27.0
        if: env.sink_failure_count > 9
        with:
          payload: |
            {
                "text": ":warning: ALERT: DataHub CaDeT metadata ingestion sink failure count is {{env.sink_failure_count}} which is above the threshold of 9 on ${{inputs.ENVIRONMENT}} ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_ALERT_WEBHOOK }}

      - name: Notify on unexpected ingestion failures
        uses: slackapi/slack-github-action@v1.27.0
        if: env.source_failure_count > 1
        with:
          payload: |
            {
                "text": ":warning: ALERT: DataHub CaDeT metadata ingestion source failure above threshold on ${{inputs.ENVIRONMENT}} ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_ALERT_WEBHOOK }}

      - name: Notify on ingestion not producing output.json or an unhandled failure
        uses: slackapi/slack-github-action@v1.27.0
        if: failure()
        with:
          payload: |
            {
                "text": ":warning: ALERT: DataHub CaDeT metadata ingestion produced no output on ${{inputs.ENVIRONMENT}} ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_ALERT_WEBHOOK }}
