name: "Ingest DBT metadata from Create a Derived Table"

permissions:
  id-token: write
  contents: read

on:
  workflow_call:
    inputs:
      ECR_REGION:
        description: "ecr region to connect to"
        required: false
        type: string
        default: eu-west-1
      ENVIRONMENT:
        description: "Environment to use for secrets"
        required: true
        type: string
    secrets:
      DATAHUB_GMS_TOKEN:
        description: "API Key for datahub GMS"
        required: true
      CADET_METADATA_ROLE_TO_ASSUME:
        description: "AWS role to assume, which can access CaDeT metadata in S3"
        required: true
      SLACK_ALERT_WEBHOOK:
        description: "Webhook for posting alerts to the team"
        required: true

jobs:
  datahub-ingest:
    environment: ${{ inputs.ENVIRONMENT }}
    timeout-minutes: 240
    runs-on: ubuntu-latest
    steps:
      - run: echo "ENVIRONMENT=${{inputs.ENVIRONMENT}}; URL=${{vars.DATAHUB_GMS_URL}}"
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.CADET_METADATA_ROLE_TO_ASSUME }}
          role-duration-seconds: 14400
          aws-region: ${{ inputs.ECR_REGION }}

      - name: cache poetry install
        uses: actions/cache@v4
        with:
          path: ~/.local
          key: poetry-1.7.1-0

      - uses: snok/install-poetry@v1
        with:
          version: 1.7.1
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: cache deps
        id: cache-deps
        uses: actions/cache@v4
        with:
          path: .venv
          key: pydeps-${{ hashFiles('**/poetry.lock') }}
      - run: poetry install --no-interaction --no-root
        if: steps.cache-deps.outputs.cache-hit != 'true'
      - run: poetry install --no-interaction

      - name: create cadet domains
        env:
          DATAHUB_GMS_TOKEN: ${{ secrets.DATAHUB_GMS_TOKEN }}
          DATAHUB_GMS_URL: ${{ vars.DATAHUB_GMS_URL }}
          DATAHUB_TELEMETRY_ENABLED: false
        run: time poetry run datahub ingest -c ingestion/create_cadet_databases.yaml

      - name: push metadata to datahub
        id: push_datahub
        env:
          DATAHUB_GMS_TOKEN: ${{ secrets.DATAHUB_GMS_TOKEN }}
          DATAHUB_GMS_URL: ${{ vars.DATAHUB_GMS_URL }}
          DATAHUB_TELEMETRY_ENABLED: false
        run: |
          time poetry run datahub ingest -c ingestion/cadet.yaml --report-to output.json || true
          if [ ! -f output.json ]; then
            echo "Ingestion output file not found. Failing the job."
            exit 1
          fi
          FAILURE_COUNT=$(jq '.sink.report.failures | length' output.json)
          echo "failure_count=$FAILURE_COUNT" >> $GITHUB_ENV

      - name: Notify on unexpected ingestion failures
        uses: slackapi/slack-github-action@v1.27.0
        if: env.failure_count > 2
        with:
          payload: |
            {
                "text": ":warning: ALERT: DataHub CaDeT metadata ingestion failure above threshold on ${{inputs.ENVIRONMENT}} ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_ALERT_WEBHOOK }}

      - name: Notify on ingestion not producing output.json or an unhandled failure
        uses: slackapi/slack-github-action@v1.27.0
        if: failure()
        with:
          payload: |
            {
                "text": ":warning: ALERT: DataHub CaDeT metadata ingestion produced no output on ${{inputs.ENVIRONMENT}} ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_ALERT_WEBHOOK }}
